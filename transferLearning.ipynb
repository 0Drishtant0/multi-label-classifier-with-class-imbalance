{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "import keras\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from sklearn.metrics import log_loss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from sklearn.utils import compute_sample_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 99\n",
    "def random_seed(SEED):\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    tf.random.set_seed(SEED)\n",
    "random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_text</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't feel original anymore.</td>\n",
       "      <td>When I was in high school a few years back, I ...</td>\n",
       "      <td>[[Feeling-bad-about-yourself-or-that-you-are-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don’t have anyone to talk to and I don’t kno...</td>\n",
       "      <td>Nine years ago I was diagnosed with depression...</td>\n",
       "      <td>[[Feeling-bad-about-yourself-or-that-you-are-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stuck between moving forward and killing myself</td>\n",
       "      <td>Some background information: My GF of almost 3...</td>\n",
       "      <td>[[Feeling-bad-about-yourself-or-that-you-are-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need help on how to help my girlfriend.</td>\n",
       "      <td>My girlfriend ,of about 3 months now ,has been...</td>\n",
       "      <td>[[Feeling-bad-about-yourself-or-that-you-are-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been feeling this way for some tine</td>\n",
       "      <td>I'm alway feeling like this. It doesn't even m...</td>\n",
       "      <td>[[Feeling-bad-about-yourself-or-that-you-are-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title  \\\n",
       "0                     I don't feel original anymore.   \n",
       "1  I don’t have anyone to talk to and I don’t kno...   \n",
       "2    Stuck between moving forward and killing myself   \n",
       "3          I need help on how to help my girlfriend.   \n",
       "4           I've been feeling this way for some tine   \n",
       "\n",
       "                                           post_text  \\\n",
       "0  When I was in high school a few years back, I ...   \n",
       "1  Nine years ago I was diagnosed with depression...   \n",
       "2  Some background information: My GF of almost 3...   \n",
       "3  My girlfriend ,of about 3 months now ,has been...   \n",
       "4  I'm alway feeling like this. It doesn't even m...   \n",
       "\n",
       "                                         annotations  \n",
       "0  [[Feeling-bad-about-yourself-or-that-you-are-a...  \n",
       "1  [[Feeling-bad-about-yourself-or-that-you-are-a...  \n",
       "2  [[Feeling-bad-about-yourself-or-that-you-are-a...  \n",
       "3  [[Feeling-bad-about-yourself-or-that-you-are-a...  \n",
       "4  [[Feeling-bad-about-yourself-or-that-you-are-a...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data1 = pd.read_json('primate_dataset.json')\n",
    "train_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1['tags'] = train_data1['annotations'].apply(lambda x: [annotation[0] for annotation in x if annotation[1] == 'yes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2003, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(train_data1['tags'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Feeling-bad-about-yourself-or-that-you-are-a-failure-or-have-let-yourself-or-your-family-down': 'Tag1', 'Feeling-down-depressed-or-hopeless': 'Tag2', 'Feeling-tired-or-having-little-energy': 'Tag3', 'Little-interest-or-pleasure-in-doing ': 'Tag4', 'Moving-or-speaking-so-slowly-that-other-people-could-have-noticed-Or-the-opposite-being-so-fidgety-or-restless-that-you-have-been-moving-around-a-lot-more-than-usual': 'Tag5', 'Poor-appetite-or-overeating': 'Tag6', 'Thoughts-that-you-would-be-better-off-dead-or-of-hurting-yourself-in-some-way': 'Tag7', 'Trouble-concentrating-on-things-such-as-reading-the-newspaper-or-watching-television': 'Tag8', 'Trouble-falling-or-staying-asleep-or-sleeping-too-much': 'Tag9'}\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame(y, columns=mlb.classes_)\n",
    "train_data1 = pd.concat([train_data1, new_data], axis=1)\n",
    "# Rename columns as tag1-tag9\n",
    "new_columns = ['Tag' + str(i+1) for i in range(9)]\n",
    "renaming_dict = dict(zip(train_data1.columns[4:], new_columns))\n",
    "train_data1.rename(columns=renaming_dict, inplace=True)\n",
    "\n",
    "# Print the renaming dictionary\n",
    "print(renaming_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>tags</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>Tag6</th>\n",
       "      <th>Tag7</th>\n",
       "      <th>Tag8</th>\n",
       "      <th>Tag9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't feel original anymore.</td>\n",
       "      <td>When I was in high school a few years back, I ...</td>\n",
       "      <td>[[Feeling-bad-about-yourself-or-that-you-are-a...</td>\n",
       "      <td>[Feeling-bad-about-yourself-or-that-you-are-a-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don’t have anyone to talk to and I don’t kno...</td>\n",
       "      <td>Nine years ago I was diagnosed with depression...</td>\n",
       "      <td>[[Feeling-bad-about-yourself-or-that-you-are-a...</td>\n",
       "      <td>[Feeling-bad-about-yourself-or-that-you-are-a-...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stuck between moving forward and killing myself</td>\n",
       "      <td>Some background information: My GF of almost 3...</td>\n",
       "      <td>[[Feeling-bad-about-yourself-or-that-you-are-a...</td>\n",
       "      <td>[Feeling-bad-about-yourself-or-that-you-are-a-...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need help on how to help my girlfriend.</td>\n",
       "      <td>My girlfriend ,of about 3 months now ,has been...</td>\n",
       "      <td>[[Feeling-bad-about-yourself-or-that-you-are-a...</td>\n",
       "      <td>[Feeling-bad-about-yourself-or-that-you-are-a-...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've been feeling this way for some tine</td>\n",
       "      <td>I'm alway feeling like this. It doesn't even m...</td>\n",
       "      <td>[[Feeling-bad-about-yourself-or-that-you-are-a...</td>\n",
       "      <td>[Feeling-bad-about-yourself-or-that-you-are-a-...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          post_title  \\\n",
       "0                     I don't feel original anymore.   \n",
       "1  I don’t have anyone to talk to and I don’t kno...   \n",
       "2    Stuck between moving forward and killing myself   \n",
       "3          I need help on how to help my girlfriend.   \n",
       "4           I've been feeling this way for some tine   \n",
       "\n",
       "                                           post_text  \\\n",
       "0  When I was in high school a few years back, I ...   \n",
       "1  Nine years ago I was diagnosed with depression...   \n",
       "2  Some background information: My GF of almost 3...   \n",
       "3  My girlfriend ,of about 3 months now ,has been...   \n",
       "4  I'm alway feeling like this. It doesn't even m...   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  [[Feeling-bad-about-yourself-or-that-you-are-a...   \n",
       "1  [[Feeling-bad-about-yourself-or-that-you-are-a...   \n",
       "2  [[Feeling-bad-about-yourself-or-that-you-are-a...   \n",
       "3  [[Feeling-bad-about-yourself-or-that-you-are-a...   \n",
       "4  [[Feeling-bad-about-yourself-or-that-you-are-a...   \n",
       "\n",
       "                                                tags  Tag1  Tag2  Tag3  Tag4  \\\n",
       "0  [Feeling-bad-about-yourself-or-that-you-are-a-...     1     0     1     1   \n",
       "1  [Feeling-bad-about-yourself-or-that-you-are-a-...     1     1     0     0   \n",
       "2  [Feeling-bad-about-yourself-or-that-you-are-a-...     1     1     1     1   \n",
       "3  [Feeling-bad-about-yourself-or-that-you-are-a-...     1     1     0     0   \n",
       "4  [Feeling-bad-about-yourself-or-that-you-are-a-...     1     1     0     0   \n",
       "\n",
       "   Tag5  Tag6  Tag7  Tag8  Tag9  \n",
       "0     0     0     0     0     0  \n",
       "1     1     0     0     0     0  \n",
       "2     0     0     1     0     0  \n",
       "3     0     0     1     0     0  \n",
       "4     0     0     0     0     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments_labels = train_data1[['Tag1','Tag2','Tag3','Tag4','Tag5', 'Tag6', 'Tag7', 'Tag8', 'Tag9']]\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 10\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "comments_labels.sum(axis=0).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Define a function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Apply the preprocessing function to the post_text column\n",
    "train_data1['processed_text'] = train_data1['post_text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name google-bert/bert-base-uncased. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3695c2fb2d2b484988463d7b24c2319b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('google-bert/bert-base-uncased')\n",
    "model.max_seq_length = 512\n",
    "print(\"Max Sequence Length:\", model.max_seq_length)\n",
    "sentence_embeddings = model.encode(train_data1['processed_text'], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(sentence_embeddings, \n",
    "                                                      comments_labels, \n",
    "                                                      train_size=0.8, \n",
    "                                                      test_size=0.2, \n",
    "                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1602, 768), (1602, 9), (401, 768), (401, 9))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-22 05:29:50,060] A new study created in memory with name: no-name-b517f5b6-2aaf-49dc-a6dc-bac24769b16d\n",
      "[I 2024-02-22 05:30:02,684] Trial 0 finished with value: 0.4864678680896759 and parameters: {'n_layers': 3, 'n_units_l0': 159, 'activation0': 'relu', 'dropout0': 0.4935792666605632, 'n_units_l1': 135, 'activation1': 'swish', 'dropout1': 0.5404243730343004, 'n_units_l2': 277, 'activation2': 'relu', 'dropout2': 0.3832874424230908, 'size': 119}. Best is trial 0 with value: 0.4864678680896759.\n",
      "[I 2024-02-22 05:30:05,506] Trial 1 finished with value: 0.46843060851097107 and parameters: {'n_layers': 1, 'n_units_l0': 751, 'activation0': 'swish', 'dropout0': 0.16695462730227428, 'size': 20}. Best is trial 1 with value: 0.46843060851097107.\n",
      "[I 2024-02-22 05:30:10,167] Trial 2 finished with value: 0.4691919684410095 and parameters: {'n_layers': 2, 'n_units_l0': 111, 'activation0': 'swish', 'dropout0': 0.35804021050239676, 'n_units_l1': 119, 'activation1': 'relu', 'dropout1': 0.03190565184468834, 'size': 9}. Best is trial 1 with value: 0.46843060851097107.\n",
      "[I 2024-02-22 05:30:14,820] Trial 3 finished with value: 0.48362380266189575 and parameters: {'n_layers': 3, 'n_units_l0': 320, 'activation0': 'relu', 'dropout0': 0.34107185699683085, 'n_units_l1': 187, 'activation1': 'linear', 'dropout1': 0.5839168392365893, 'n_units_l2': 96, 'activation2': 'swish', 'dropout2': 0.5979192106447332, 'size': 76}. Best is trial 1 with value: 0.46843060851097107.\n",
      "[I 2024-02-22 05:30:16,870] Trial 4 finished with value: 0.4674883782863617 and parameters: {'n_layers': 2, 'n_units_l0': 453, 'activation0': 'linear', 'dropout0': 0.4150192947036215, 'n_units_l1': 308, 'activation1': 'linear', 'dropout1': 0.005308410061800317, 'size': 55}. Best is trial 4 with value: 0.4674883782863617.\n",
      "[I 2024-02-22 05:30:21,537] Trial 5 finished with value: 0.47817859053611755 and parameters: {'n_layers': 3, 'n_units_l0': 593, 'activation0': 'linear', 'dropout0': 0.024483849414060076, 'n_units_l1': 49, 'activation1': 'swish', 'dropout1': 0.3228832140469423, 'n_units_l2': 287, 'activation2': 'swish', 'dropout2': 0.5571649035758306, 'size': 27}. Best is trial 4 with value: 0.4674883782863617.\n",
      "[I 2024-02-22 05:30:23,894] Trial 6 finished with value: 0.4713054895401001 and parameters: {'n_layers': 2, 'n_units_l0': 688, 'activation0': 'relu', 'dropout0': 0.23237461489601957, 'n_units_l1': 459, 'activation1': 'relu', 'dropout1': 0.23449749019774846, 'size': 43}. Best is trial 4 with value: 0.4674883782863617.\n",
      "[I 2024-02-22 05:30:26,208] Trial 7 finished with value: 0.4744992256164551 and parameters: {'n_layers': 3, 'n_units_l0': 94, 'activation0': 'swish', 'dropout0': 0.27872378241218393, 'n_units_l1': 189, 'activation1': 'swish', 'dropout1': 0.2977622347208649, 'n_units_l2': 131, 'activation2': 'linear', 'dropout2': 0.23694049839857342, 'size': 82}. Best is trial 4 with value: 0.4674883782863617.\n",
      "[I 2024-02-22 05:30:27,734] Trial 8 finished with value: 0.47031980752944946 and parameters: {'n_layers': 1, 'n_units_l0': 242, 'activation0': 'swish', 'dropout0': 0.1929760137642116, 'size': 58}. Best is trial 4 with value: 0.4674883782863617.\n",
      "[I 2024-02-22 05:30:29,843] Trial 9 finished with value: 0.47120147943496704 and parameters: {'n_layers': 1, 'n_units_l0': 195, 'activation0': 'relu', 'dropout0': 0.3729143406711724, 'size': 31}. Best is trial 4 with value: 0.4674883782863617.\n",
      "[I 2024-02-22 05:30:33,397] Trial 10 finished with value: 0.4736228287220001 and parameters: {'n_layers': 2, 'n_units_l0': 48, 'activation0': 'linear', 'dropout0': 0.5967828285320953, 'n_units_l1': 740, 'activation1': 'linear', 'dropout1': 0.008176960386869964, 'size': 96}. Best is trial 4 with value: 0.4674883782863617.\n",
      "[I 2024-02-22 05:30:38,618] Trial 11 finished with value: 0.4655420780181885 and parameters: {'n_layers': 1, 'n_units_l0': 440, 'activation0': 'linear', 'dropout0': 0.057245189944336916, 'size': 11}. Best is trial 11 with value: 0.4655420780181885.\n",
      "[I 2024-02-22 05:30:40,527] Trial 12 finished with value: 0.468196302652359 and parameters: {'n_layers': 1, 'n_units_l0': 388, 'activation0': 'linear', 'dropout0': 0.002126351130019577, 'size': 56}. Best is trial 11 with value: 0.4655420780181885.\n",
      "[I 2024-02-22 05:30:42,296] Trial 13 finished with value: 0.468082070350647 and parameters: {'n_layers': 2, 'n_units_l0': 412, 'activation0': 'linear', 'dropout0': 0.4608422891660622, 'n_units_l1': 364, 'activation1': 'linear', 'dropout1': 0.16599534777941202, 'size': 47}. Best is trial 11 with value: 0.4655420780181885.\n",
      "[I 2024-02-22 05:30:43,804] Trial 14 finished with value: 0.46601924300193787 and parameters: {'n_layers': 1, 'n_units_l0': 489, 'activation0': 'linear', 'dropout0': 0.09562566152896707, 'size': 103}. Best is trial 11 with value: 0.4655420780181885.\n",
      "[I 2024-02-22 05:30:45,612] Trial 15 finished with value: 0.4702010154724121 and parameters: {'n_layers': 1, 'n_units_l0': 275, 'activation0': 'linear', 'dropout0': 0.10917123364216072, 'size': 126}. Best is trial 11 with value: 0.4655420780181885.\n",
      "[I 2024-02-22 05:30:47,181] Trial 16 finished with value: 0.4679644703865051 and parameters: {'n_layers': 1, 'n_units_l0': 524, 'activation0': 'linear', 'dropout0': 0.09572767144761435, 'size': 95}. Best is trial 11 with value: 0.4655420780181885.\n",
      "[I 2024-02-22 05:30:48,661] Trial 17 finished with value: 0.4680922031402588 and parameters: {'n_layers': 1, 'n_units_l0': 328, 'activation0': 'linear', 'dropout0': 0.0879336331633577, 'size': 113}. Best is trial 11 with value: 0.4655420780181885.\n",
      "[I 2024-02-22 05:30:49,759] Trial 18 finished with value: 0.4748718738555908 and parameters: {'n_layers': 1, 'n_units_l0': 202, 'activation0': 'linear', 'dropout0': 0.1390588424354367, 'size': 98}. Best is trial 11 with value: 0.4655420780181885.\n",
      "[I 2024-02-22 05:30:51,414] Trial 19 finished with value: 0.4758801758289337 and parameters: {'n_layers': 2, 'n_units_l0': 131, 'activation0': 'linear', 'dropout0': 0.05384577485474887, 'n_units_l1': 53, 'activation1': 'relu', 'dropout1': 0.4449846285267316, 'size': 74}. Best is trial 11 with value: 0.4655420780181885.\n",
      "[I 2024-02-22 05:30:52,585] Trial 20 finished with value: 0.47644975781440735 and parameters: {'n_layers': 1, 'n_units_l0': 73, 'activation0': 'linear', 'dropout0': 0.23905469120529388, 'size': 107}. Best is trial 11 with value: 0.4655420780181885.\n",
      "[I 2024-02-22 05:30:57,795] Trial 21 finished with value: 0.46436256170272827 and parameters: {'n_layers': 2, 'n_units_l0': 491, 'activation0': 'linear', 'dropout0': 0.46643230001285607, 'n_units_l1': 322, 'activation1': 'linear', 'dropout1': 0.12603531909916463, 'size': 10}. Best is trial 21 with value: 0.46436256170272827.\n",
      "[I 2024-02-22 05:31:04,231] Trial 22 finished with value: 0.46495312452316284 and parameters: {'n_layers': 2, 'n_units_l0': 528, 'activation0': 'linear', 'dropout0': 0.571400954781476, 'n_units_l1': 702, 'activation1': 'linear', 'dropout1': 0.13062822858606393, 'size': 9}. Best is trial 21 with value: 0.46436256170272827.\n",
      "[I 2024-02-22 05:31:11,351] Trial 23 finished with value: 0.4659821689128876 and parameters: {'n_layers': 2, 'n_units_l0': 605, 'activation0': 'linear', 'dropout0': 0.596324473343433, 'n_units_l1': 729, 'activation1': 'linear', 'dropout1': 0.13698508796641917, 'size': 8}. Best is trial 21 with value: 0.46436256170272827.\n",
      "[I 2024-02-22 05:31:19,441] Trial 24 finished with value: 0.46601414680480957 and parameters: {'n_layers': 2, 'n_units_l0': 347, 'activation0': 'linear', 'dropout0': 0.5381589594705855, 'n_units_l1': 452, 'activation1': 'linear', 'dropout1': 0.10638324663849028, 'size': 18}. Best is trial 21 with value: 0.46436256170272827.\n",
      "[I 2024-02-22 05:31:24,506] Trial 25 finished with value: 0.46815529465675354 and parameters: {'n_layers': 2, 'n_units_l0': 244, 'activation0': 'linear', 'dropout0': 0.5253254703727392, 'n_units_l1': 260, 'activation1': 'linear', 'dropout1': 0.22642599253350448, 'size': 34}. Best is trial 21 with value: 0.46436256170272827.\n",
      "[I 2024-02-22 05:31:28,561] Trial 26 finished with value: 0.46743422746658325 and parameters: {'n_layers': 3, 'n_units_l0': 574, 'activation0': 'linear', 'dropout0': 0.4470729838390017, 'n_units_l1': 571, 'activation1': 'linear', 'dropout1': 0.09350220150976901, 'n_units_l2': 754, 'activation2': 'linear', 'dropout2': 0.01763247478086144, 'size': 18}. Best is trial 21 with value: 0.46436256170272827.\n",
      "[I 2024-02-22 05:31:35,912] Trial 27 finished with value: 0.4658225476741791 and parameters: {'n_layers': 2, 'n_units_l0': 401, 'activation0': 'linear', 'dropout0': 0.5437764566049794, 'n_units_l1': 276, 'activation1': 'linear', 'dropout1': 0.37109477031044547, 'size': 8}. Best is trial 21 with value: 0.46436256170272827.\n",
      "[I 2024-02-22 05:31:38,668] Trial 28 finished with value: 0.4684320390224457 and parameters: {'n_layers': 2, 'n_units_l0': 678, 'activation0': 'swish', 'dropout0': 0.4094337635737357, 'n_units_l1': 87, 'activation1': 'linear', 'dropout1': 0.20632812996647548, 'size': 36}. Best is trial 21 with value: 0.46436256170272827.\n",
      "[I 2024-02-22 05:31:58,860] Trial 29 finished with value: 0.48437798023223877 and parameters: {'n_layers': 3, 'n_units_l0': 148, 'activation0': 'relu', 'dropout0': 0.4885182026796703, 'n_units_l1': 546, 'activation1': 'relu', 'dropout1': 0.10335470401861062, 'n_units_l2': 49, 'activation2': 'relu', 'dropout2': 0.01946963991210282, 'size': 23}. Best is trial 21 with value: 0.46436256170272827.\n",
      "[I 2024-02-22 05:32:03,279] Trial 30 finished with value: 0.47252437472343445 and parameters: {'n_layers': 3, 'n_units_l0': 490, 'activation0': 'relu', 'dropout0': 0.3111620687419897, 'n_units_l1': 419, 'activation1': 'swish', 'dropout1': 0.26826292698088605, 'n_units_l2': 725, 'activation2': 'linear', 'dropout2': 0.2370261063371537, 'size': 15}. Best is trial 21 with value: 0.46436256170272827.\n",
      "[I 2024-02-22 05:32:12,357] Trial 31 finished with value: 0.46387723088264465 and parameters: {'n_layers': 2, 'n_units_l0': 393, 'activation0': 'linear', 'dropout0': 0.5608378675915191, 'n_units_l1': 264, 'activation1': 'linear', 'dropout1': 0.3958831427667795, 'size': 10}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:32:15,126] Trial 32 finished with value: 0.4648960530757904 and parameters: {'n_layers': 2, 'n_units_l0': 300, 'activation0': 'linear', 'dropout0': 0.5598001937713784, 'n_units_l1': 239, 'activation1': 'linear', 'dropout1': 0.41875969092260695, 'size': 26}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:32:19,832] Trial 33 finished with value: 0.4674244821071625 and parameters: {'n_layers': 2, 'n_units_l0': 270, 'activation0': 'linear', 'dropout0': 0.5771059556588236, 'n_units_l1': 232, 'activation1': 'linear', 'dropout1': 0.4321203590705722, 'size': 24}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:32:22,615] Trial 34 finished with value: 0.4688141644001007 and parameters: {'n_layers': 2, 'n_units_l0': 307, 'activation0': 'swish', 'dropout0': 0.5014485612404844, 'n_units_l1': 209, 'activation1': 'linear', 'dropout1': 0.43118844749742496, 'size': 40}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:32:26,328] Trial 35 finished with value: 0.46941155195236206 and parameters: {'n_layers': 2, 'n_units_l0': 368, 'activation0': 'linear', 'dropout0': 0.5733542157915005, 'n_units_l1': 344, 'activation1': 'linear', 'dropout1': 0.37253553058901356, 'size': 19}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:32:30,662] Trial 36 finished with value: 0.46787986159324646 and parameters: {'n_layers': 2, 'n_units_l0': 750, 'activation0': 'linear', 'dropout0': 0.48437107731465634, 'n_units_l1': 155, 'activation1': 'linear', 'dropout1': 0.49820575652359095, 'size': 14}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:32:36,520] Trial 37 finished with value: 0.46681442856788635 and parameters: {'n_layers': 2, 'n_units_l0': 223, 'activation0': 'linear', 'dropout0': 0.5509808753237199, 'n_units_l1': 296, 'activation1': 'linear', 'dropout1': 0.3678084520719366, 'size': 29}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:32:50,332] Trial 38 finished with value: 0.4732682704925537 and parameters: {'n_layers': 2, 'n_units_l0': 543, 'activation0': 'relu', 'dropout0': 0.43286562219145974, 'n_units_l1': 96, 'activation1': 'linear', 'dropout1': 0.47851510592090246, 'size': 25}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:32:53,334] Trial 39 finished with value: 0.46805471181869507 and parameters: {'n_layers': 2, 'n_units_l0': 292, 'activation0': 'swish', 'dropout0': 0.5076830799551646, 'n_units_l1': 242, 'activation1': 'linear', 'dropout1': 0.33951653954906846, 'size': 48}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:32:54,903] Trial 40 finished with value: 0.46646103262901306 and parameters: {'n_layers': 2, 'n_units_l0': 640, 'activation0': 'linear', 'dropout0': 0.3913427623311381, 'n_units_l1': 580, 'activation1': 'linear', 'dropout1': 0.16933565141526333, 'size': 65}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:34:13,658] Trial 41 finished with value: 0.48244234919548035 and parameters: {'n_layers': 3, 'n_units_l0': 444, 'activation0': 'linear', 'dropout0': 0.567263414968259, 'n_units_l1': 148, 'activation1': 'swish', 'dropout1': 0.5348703946180833, 'n_units_l2': 52, 'activation2': 'swish', 'dropout2': 0.401241206906447, 'size': 8}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:34:18,529] Trial 42 finished with value: 0.464293897151947 and parameters: {'n_layers': 2, 'n_units_l0': 456, 'activation0': 'linear', 'dropout0': 0.5183037879649977, 'n_units_l1': 376, 'activation1': 'linear', 'dropout1': 0.06639762272831118, 'size': 13}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:34:23,119] Trial 43 finished with value: 0.4655129611492157 and parameters: {'n_layers': 2, 'n_units_l0': 343, 'activation0': 'linear', 'dropout0': 0.47004563333014904, 'n_units_l1': 367, 'activation1': 'linear', 'dropout1': 0.405685012801285, 'size': 14}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:34:30,288] Trial 44 finished with value: 0.46618956327438354 and parameters: {'n_layers': 2, 'n_units_l0': 469, 'activation0': 'linear', 'dropout0': 0.5189137945040192, 'n_units_l1': 321, 'activation1': 'linear', 'dropout1': 0.07907312971498259, 'size': 22}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:34:32,069] Trial 45 finished with value: 0.466468870639801 and parameters: {'n_layers': 2, 'n_units_l0': 766, 'activation0': 'linear', 'dropout0': 0.5533863788786276, 'n_units_l1': 175, 'activation1': 'linear', 'dropout1': 0.04715190241721064, 'size': 32}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:34:35,363] Trial 46 finished with value: 0.4667554795742035 and parameters: {'n_layers': 2, 'n_units_l0': 393, 'activation0': 'swish', 'dropout0': 0.33671761219788743, 'n_units_l1': 402, 'activation1': 'relu', 'dropout1': 0.04719759310577487, 'size': 13}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:34:47,553] Trial 47 finished with value: 0.4726738929748535 and parameters: {'n_layers': 2, 'n_units_l0': 523, 'activation0': 'relu', 'dropout0': 0.5926125993191683, 'n_units_l1': 222, 'activation1': 'linear', 'dropout1': 0.15037432356711725, 'size': 27}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:34:49,422] Trial 48 finished with value: 0.46848422288894653 and parameters: {'n_layers': 2, 'n_units_l0': 452, 'activation0': 'linear', 'dropout0': 0.5219904366871654, 'n_units_l1': 527, 'activation1': 'linear', 'dropout1': 0.06407981958718105, 'size': 40}. Best is trial 31 with value: 0.46387723088264465.\n",
      "[I 2024-02-22 05:34:53,764] Trial 49 finished with value: 0.4697231352329254 and parameters: {'n_layers': 2, 'n_units_l0': 605, 'activation0': 'linear', 'dropout0': 0.43400196984585715, 'n_units_l1': 282, 'activation1': 'swish', 'dropout1': 0.12101968794658045, 'size': 19}. Best is trial 31 with value: 0.46387723088264465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 50\n",
      "Best trial:\n",
      "  Value: 0.46387723088264465\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    keras.backend.clear_session()\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, train_size=0.8, test_size=0.2,\n",
    "                                                                                        random_state=42)\n",
    "\n",
    "\n",
    "    #optimum number of hidden layers\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    model = keras.Sequential()\n",
    "    for i in range(n_layers):\n",
    "        #optimum number of hidden nodes\n",
    "        num_hidden = trial.suggest_int(f'n_units_l{i}', 48, len(sentence_embeddings[0]), log=True)\n",
    "        #optimum activation function\n",
    "        model.add(keras.layers.Dense(num_hidden, input_shape=(len(sentence_embeddings[0]),),\n",
    "                               activation=trial.suggest_categorical(f'activation{i}', ['relu', 'linear','swish'])))\n",
    "        #optimum dropout value\n",
    "        model.add(keras.layers.Dropout(rate = trial.suggest_float(f'dropout{i}', 0.0, 0.6))) \n",
    "    model.add(keras.layers.Dense(9,activation=tf.keras.activations.sigmoid)) #output Layer\n",
    "    val_ds = (x_valid,y_valid)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=1,min_lr=1e-05,verbose=0)\n",
    "    early_stoping = EarlyStopping(monitor=\"val_loss\",min_delta=0,patience=5,verbose=0,mode=\"auto\", baseline=None,restore_best_weights=True)\n",
    "    model.compile(loss='binary_crossentropy',metrics='categorical_crossentropy', optimizer='Adam')\n",
    "    #optimum batch size\n",
    "    histroy = model.fit(x_train,y_train, validation_data=val_ds,epochs=200,callbacks=[reduce_lr,early_stoping],verbose=0,\n",
    "                       batch_size=trial.suggest_int('size', 8, 128))\n",
    "    return min(histroy.history['val_loss'])\n",
    "if __name__ == \"__main__\":\n",
    "  study = optuna.create_study(direction=\"minimize\")\n",
    "  study.optimize(objective, n_trials=50, timeout=1200)\n",
    "  print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "  print(\"Best trial:\")\n",
    "  trial = study.best_trial\n",
    "  print(\"  Value: {}\".format(trial.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          0.4864678680896759,
          0.46843060851097107,
          0.4691919684410095,
          0.48362380266189575,
          0.4674883782863617,
          0.47817859053611755,
          0.4713054895401001,
          0.4744992256164551,
          0.47031980752944946,
          0.47120147943496704,
          0.4736228287220001,
          0.4655420780181885,
          0.468196302652359,
          0.468082070350647,
          0.46601924300193787,
          0.4702010154724121,
          0.4679644703865051,
          0.4680922031402588,
          0.4748718738555908,
          0.4758801758289337,
          0.47644975781440735,
          0.46436256170272827,
          0.46495312452316284,
          0.4659821689128876,
          0.46601414680480957,
          0.46815529465675354,
          0.46743422746658325,
          0.4658225476741791,
          0.4684320390224457,
          0.48437798023223877,
          0.47252437472343445,
          0.46387723088264465,
          0.4648960530757904,
          0.4674244821071625,
          0.4688141644001007,
          0.46941155195236206,
          0.46787986159324646,
          0.46681442856788635,
          0.4732682704925537,
          0.46805471181869507,
          0.46646103262901306,
          0.48244234919548035,
          0.464293897151947,
          0.4655129611492157,
          0.46618956327438354,
          0.466468870639801,
          0.4667554795742035,
          0.4726738929748535,
          0.46848422288894653,
          0.4697231352329254
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "y": [
          0.4864678680896759,
          0.46843060851097107,
          0.46843060851097107,
          0.46843060851097107,
          0.4674883782863617,
          0.4674883782863617,
          0.4674883782863617,
          0.4674883782863617,
          0.4674883782863617,
          0.4674883782863617,
          0.4674883782863617,
          0.4655420780181885,
          0.4655420780181885,
          0.4655420780181885,
          0.4655420780181885,
          0.4655420780181885,
          0.4655420780181885,
          0.4655420780181885,
          0.4655420780181885,
          0.4655420780181885,
          0.4655420780181885,
          0.46436256170272827,
          0.46436256170272827,
          0.46436256170272827,
          0.46436256170272827,
          0.46436256170272827,
          0.46436256170272827,
          0.46436256170272827,
          0.46436256170272827,
          0.46436256170272827,
          0.46436256170272827,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465,
          0.46387723088264465
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Params: \n",
      "    n_layers: 2\n",
      "    n_units_l0: 393\n",
      "    activation0: linear\n",
      "    dropout0: 0.5608378675915191\n",
      "    n_units_l1: 264\n",
      "    activation1: linear\n",
      "    dropout1: 0.3958831427667795\n",
      "    size: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "  print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wider_model():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(393, input_shape=(len(sentence_embeddings[0]),), activation='linear'))\n",
    "    model.add(keras.layers.Dropout(0.5608378675915191))\n",
    "    model.add(keras.layers.Dense(264, activation='linear'))\n",
    "    model.add(keras.layers.Dropout(0.3958831427667795))\n",
    "    model.add(keras.layers.Dense(9,activation=tf.keras.activations.sigmoid))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################\n",
      "1\n",
      "#################\n",
      "Epoch 1/200\n",
      "42/42 [==============================] - 1s 9ms/step - loss: 0.5855 - categorical_crossentropy: 9.4211 - val_loss: 0.4752 - val_categorical_crossentropy: 8.9059 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.5004 - categorical_crossentropy: 8.6077 - val_loss: 0.4572 - val_categorical_crossentropy: 7.9023 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.4857 - categorical_crossentropy: 8.2503\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4872 - categorical_crossentropy: 8.2563 - val_loss: 0.4612 - val_categorical_crossentropy: 7.5629 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4625 - categorical_crossentropy: 8.0230 - val_loss: 0.4509 - val_categorical_crossentropy: 7.6931 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "30/42 [====================>.........] - ETA: 0s - loss: 0.4557 - categorical_crossentropy: 7.9606\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4528 - categorical_crossentropy: 7.8778 - val_loss: 0.4518 - val_categorical_crossentropy: 7.8171 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.4452 - categorical_crossentropy: 7.8956\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4467 - categorical_crossentropy: 7.8818 - val_loss: 0.4510 - val_categorical_crossentropy: 7.8030 - lr: 1.0000e-05\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4467 - categorical_crossentropy: 7.8650 - val_loss: 0.4510 - val_categorical_crossentropy: 7.7833 - lr: 1.0000e-05\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4465 - categorical_crossentropy: 7.8643 - val_loss: 0.4505 - val_categorical_crossentropy: 7.7612 - lr: 1.0000e-05\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4443 - categorical_crossentropy: 7.7985 - val_loss: 0.4505 - val_categorical_crossentropy: 7.7519 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4447 - categorical_crossentropy: 7.8056 - val_loss: 0.4504 - val_categorical_crossentropy: 7.7320 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4440 - categorical_crossentropy: 7.7910 - val_loss: 0.4502 - val_categorical_crossentropy: 7.7384 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4431 - categorical_crossentropy: 7.7356 - val_loss: 0.4502 - val_categorical_crossentropy: 7.7421 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4410 - categorical_crossentropy: 7.7755 - val_loss: 0.4500 - val_categorical_crossentropy: 7.7236 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4403 - categorical_crossentropy: 7.7081 - val_loss: 0.4500 - val_categorical_crossentropy: 7.7311 - lr: 1.0000e-05\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4389 - categorical_crossentropy: 7.7487 - val_loss: 0.4497 - val_categorical_crossentropy: 7.7629 - lr: 1.0000e-05\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4403 - categorical_crossentropy: 7.7349 - val_loss: 0.4498 - val_categorical_crossentropy: 7.7352 - lr: 1.0000e-05\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4435 - categorical_crossentropy: 7.8319 - val_loss: 0.4498 - val_categorical_crossentropy: 7.7157 - lr: 1.0000e-05\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4390 - categorical_crossentropy: 7.6970 - val_loss: 0.4499 - val_categorical_crossentropy: 7.7167 - lr: 1.0000e-05\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4403 - categorical_crossentropy: 7.7289 - val_loss: 0.4497 - val_categorical_crossentropy: 7.7162 - lr: 1.0000e-05\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4418 - categorical_crossentropy: 7.7083 - val_loss: 0.4499 - val_categorical_crossentropy: 7.7540 - lr: 1.0000e-05\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4415 - categorical_crossentropy: 7.7566 - val_loss: 0.4496 - val_categorical_crossentropy: 7.7321 - lr: 1.0000e-05\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4383 - categorical_crossentropy: 7.7223 - val_loss: 0.4495 - val_categorical_crossentropy: 7.7359 - lr: 1.0000e-05\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4360 - categorical_crossentropy: 7.7259 - val_loss: 0.4496 - val_categorical_crossentropy: 7.7244 - lr: 1.0000e-05\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4368 - categorical_crossentropy: 7.7038 - val_loss: 0.4493 - val_categorical_crossentropy: 7.7518 - lr: 1.0000e-05\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4399 - categorical_crossentropy: 7.7490 - val_loss: 0.4495 - val_categorical_crossentropy: 7.7719 - lr: 1.0000e-05\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4355 - categorical_crossentropy: 7.7326 - val_loss: 0.4495 - val_categorical_crossentropy: 7.7757 - lr: 1.0000e-05\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4398 - categorical_crossentropy: 7.7873 - val_loss: 0.4495 - val_categorical_crossentropy: 7.7748 - lr: 1.0000e-05\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4421 - categorical_crossentropy: 7.7353 - val_loss: 0.4497 - val_categorical_crossentropy: 7.7105 - lr: 1.0000e-05\n",
      "Epoch 29/200\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.4350 - categorical_crossentropy: 7.7071Restoring model weights from the end of the best epoch: 24.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4356 - categorical_crossentropy: 7.7083 - val_loss: 0.4494 - val_categorical_crossentropy: 7.7256 - lr: 1.0000e-05\n",
      "Epoch 29: early stopping\n",
      "0.44930943846702576\n",
      "13/13 [==============================] - 0s 921us/step\n",
      "#################\n",
      "2\n",
      "#################\n",
      "Epoch 1/200\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5571 - categorical_crossentropy: 9.0388 - val_loss: 0.5289 - val_categorical_crossentropy: 8.2194 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.5112 - categorical_crossentropy: 8.5155 - val_loss: 0.4714 - val_categorical_crossentropy: 7.2393 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.4869 - categorical_crossentropy: 8.5222\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4843 - categorical_crossentropy: 8.4768 - val_loss: 0.4719 - val_categorical_crossentropy: 7.4486 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4626 - categorical_crossentropy: 8.0438 - val_loss: 0.4654 - val_categorical_crossentropy: 8.0183 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4533 - categorical_crossentropy: 8.0963 - val_loss: 0.4622 - val_categorical_crossentropy: 7.7558 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4449 - categorical_crossentropy: 7.9094 - val_loss: 0.4621 - val_categorical_crossentropy: 7.7467 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4400 - categorical_crossentropy: 7.8690 - val_loss: 0.4609 - val_categorical_crossentropy: 7.8484 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4427 - categorical_crossentropy: 7.8822 - val_loss: 0.4604 - val_categorical_crossentropy: 7.7359 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.4380 - categorical_crossentropy: 7.9210\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4395 - categorical_crossentropy: 7.9169 - val_loss: 0.4632 - val_categorical_crossentropy: 8.0178 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.4324 - categorical_crossentropy: 7.9224\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4317 - categorical_crossentropy: 7.9275 - val_loss: 0.4611 - val_categorical_crossentropy: 7.8347 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4347 - categorical_crossentropy: 7.8435 - val_loss: 0.4602 - val_categorical_crossentropy: 7.7488 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4333 - categorical_crossentropy: 7.8208 - val_loss: 0.4597 - val_categorical_crossentropy: 7.7075 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4324 - categorical_crossentropy: 7.7715 - val_loss: 0.4598 - val_categorical_crossentropy: 7.7097 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4326 - categorical_crossentropy: 7.7918 - val_loss: 0.4598 - val_categorical_crossentropy: 7.7370 - lr: 1.0000e-05\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4300 - categorical_crossentropy: 7.8183 - val_loss: 0.4600 - val_categorical_crossentropy: 7.7709 - lr: 1.0000e-05\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4342 - categorical_crossentropy: 7.8580 - val_loss: 0.4598 - val_categorical_crossentropy: 7.7446 - lr: 1.0000e-05\n",
      "Epoch 17/200\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.4327 - categorical_crossentropy: 7.8348Restoring model weights from the end of the best epoch: 12.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4304 - categorical_crossentropy: 7.7555 - val_loss: 0.4600 - val_categorical_crossentropy: 7.7532 - lr: 1.0000e-05\n",
      "Epoch 17: early stopping\n",
      "0.45974260568618774\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "#################\n",
      "3\n",
      "#################\n",
      "Epoch 1/200\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5778 - categorical_crossentropy: 9.2975 - val_loss: 0.4759 - val_categorical_crossentropy: 8.4187 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5018 - categorical_crossentropy: 8.5160 - val_loss: 0.4693 - val_categorical_crossentropy: 7.4112 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4947 - categorical_crossentropy: 8.4343 - val_loss: 0.4525 - val_categorical_crossentropy: 7.7339 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.4835 - categorical_crossentropy: 8.4081\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4835 - categorical_crossentropy: 8.4212 - val_loss: 0.4565 - val_categorical_crossentropy: 8.2782 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4558 - categorical_crossentropy: 8.1906 - val_loss: 0.4499 - val_categorical_crossentropy: 7.7430 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4434 - categorical_crossentropy: 7.9720 - val_loss: 0.4460 - val_categorical_crossentropy: 7.5404 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4390 - categorical_crossentropy: 7.8562 - val_loss: 0.4440 - val_categorical_crossentropy: 7.5306 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "28/42 [===================>..........] - ETA: 0s - loss: 0.4337 - categorical_crossentropy: 7.8811\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4339 - categorical_crossentropy: 7.8023 - val_loss: 0.4469 - val_categorical_crossentropy: 7.9291 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.4316 - categorical_crossentropy: 7.8862\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4343 - categorical_crossentropy: 7.9135 - val_loss: 0.4448 - val_categorical_crossentropy: 7.7788 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4307 - categorical_crossentropy: 7.7344 - val_loss: 0.4441 - val_categorical_crossentropy: 7.7200 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4317 - categorical_crossentropy: 7.7898 - val_loss: 0.4439 - val_categorical_crossentropy: 7.7609 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4327 - categorical_crossentropy: 7.8299 - val_loss: 0.4440 - val_categorical_crossentropy: 7.7376 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4311 - categorical_crossentropy: 7.7403 - val_loss: 0.4438 - val_categorical_crossentropy: 7.7359 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4288 - categorical_crossentropy: 7.6986 - val_loss: 0.4437 - val_categorical_crossentropy: 7.7739 - lr: 1.0000e-05\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4286 - categorical_crossentropy: 7.7255 - val_loss: 0.4433 - val_categorical_crossentropy: 7.7526 - lr: 1.0000e-05\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4286 - categorical_crossentropy: 7.7880 - val_loss: 0.4432 - val_categorical_crossentropy: 7.7797 - lr: 1.0000e-05\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4291 - categorical_crossentropy: 7.7446 - val_loss: 0.4434 - val_categorical_crossentropy: 7.7827 - lr: 1.0000e-05\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4282 - categorical_crossentropy: 7.7308 - val_loss: 0.4432 - val_categorical_crossentropy: 7.7810 - lr: 1.0000e-05\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4294 - categorical_crossentropy: 7.8320 - val_loss: 0.4434 - val_categorical_crossentropy: 7.7579 - lr: 1.0000e-05\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4285 - categorical_crossentropy: 7.7483 - val_loss: 0.4435 - val_categorical_crossentropy: 7.7656 - lr: 1.0000e-05\n",
      "Epoch 21/200\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.4266 - categorical_crossentropy: 7.6547Restoring model weights from the end of the best epoch: 16.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4272 - categorical_crossentropy: 7.6965 - val_loss: 0.4433 - val_categorical_crossentropy: 7.7595 - lr: 1.0000e-05\n",
      "Epoch 21: early stopping\n",
      "0.44319602847099304\n",
      "13/13 [==============================] - 0s 1ms/step\n",
      "#################\n",
      "4\n",
      "#################\n",
      "Epoch 1/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.5890 - categorical_crossentropy: 9.3291 - val_loss: 0.5086 - val_categorical_crossentropy: 7.5908 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5085 - categorical_crossentropy: 8.4341 - val_loss: 0.4877 - val_categorical_crossentropy: 7.6884 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4841 - categorical_crossentropy: 8.2956 - val_loss: 0.4773 - val_categorical_crossentropy: 8.2437 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.4713 - categorical_crossentropy: 8.2620\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4703 - categorical_crossentropy: 8.3301 - val_loss: 0.4855 - val_categorical_crossentropy: 9.0708 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4549 - categorical_crossentropy: 8.1491 - val_loss: 0.4739 - val_categorical_crossentropy: 8.1667 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4439 - categorical_crossentropy: 7.9783 - val_loss: 0.4738 - val_categorical_crossentropy: 8.3383 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4362 - categorical_crossentropy: 7.8758 - val_loss: 0.4736 - val_categorical_crossentropy: 8.0753 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.4323 - categorical_crossentropy: 7.7076\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4325 - categorical_crossentropy: 7.7229 - val_loss: 0.4751 - val_categorical_crossentropy: 8.1676 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "37/42 [=========================>....] - ETA: 0s - loss: 0.4342 - categorical_crossentropy: 7.7249\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4330 - categorical_crossentropy: 7.7310 - val_loss: 0.4742 - val_categorical_crossentropy: 8.2599 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4330 - categorical_crossentropy: 7.8302 - val_loss: 0.4740 - val_categorical_crossentropy: 8.2459 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4270 - categorical_crossentropy: 7.7988 - val_loss: 0.4739 - val_categorical_crossentropy: 8.2386 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "22/42 [==============>...............] - ETA: 0s - loss: 0.4300 - categorical_crossentropy: 7.7005Restoring model weights from the end of the best epoch: 7.\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4271 - categorical_crossentropy: 7.7021 - val_loss: 0.4739 - val_categorical_crossentropy: 8.2506 - lr: 1.0000e-05\n",
      "Epoch 12: early stopping\n",
      "0.4736473858356476\n",
      "13/13 [==============================] - 0s 917us/step\n",
      "#################\n",
      "5\n",
      "#################\n",
      "Epoch 1/200\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 0.5779 - categorical_crossentropy: 9.2399 - val_loss: 0.4661 - val_categorical_crossentropy: 7.2634 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.5096 - categorical_crossentropy: 8.6662\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5079 - categorical_crossentropy: 8.5997 - val_loss: 0.4752 - val_categorical_crossentropy: 8.4627 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4815 - categorical_crossentropy: 8.3071 - val_loss: 0.4545 - val_categorical_crossentropy: 7.7337 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4615 - categorical_crossentropy: 7.9820 - val_loss: 0.4537 - val_categorical_crossentropy: 7.5068 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4565 - categorical_crossentropy: 7.8805 - val_loss: 0.4516 - val_categorical_crossentropy: 7.4452 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.4485 - categorical_crossentropy: 7.8981\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4533 - categorical_crossentropy: 7.8597 - val_loss: 0.4519 - val_categorical_crossentropy: 7.3837 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4500 - categorical_crossentropy: 7.8000 - val_loss: 0.4512 - val_categorical_crossentropy: 7.3654 - lr: 1.0000e-05\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4473 - categorical_crossentropy: 7.7664 - val_loss: 0.4507 - val_categorical_crossentropy: 7.3920 - lr: 1.0000e-05\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4510 - categorical_crossentropy: 7.8747 - val_loss: 0.4503 - val_categorical_crossentropy: 7.3957 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4502 - categorical_crossentropy: 7.8033 - val_loss: 0.4500 - val_categorical_crossentropy: 7.3836 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.4518 - categorical_crossentropy: 7.8247\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4513 - categorical_crossentropy: 7.8224 - val_loss: 0.4501 - val_categorical_crossentropy: 7.3770 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4476 - categorical_crossentropy: 7.7933 - val_loss: 0.4501 - val_categorical_crossentropy: 7.3856 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4469 - categorical_crossentropy: 7.7257 - val_loss: 0.4500 - val_categorical_crossentropy: 7.3749 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4477 - categorical_crossentropy: 7.7599 - val_loss: 0.4499 - val_categorical_crossentropy: 7.4061 - lr: 1.0000e-05\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4473 - categorical_crossentropy: 7.8184 - val_loss: 0.4499 - val_categorical_crossentropy: 7.3920 - lr: 1.0000e-05\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4479 - categorical_crossentropy: 7.7620 - val_loss: 0.4498 - val_categorical_crossentropy: 7.3878 - lr: 1.0000e-05\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4446 - categorical_crossentropy: 7.7926 - val_loss: 0.4498 - val_categorical_crossentropy: 7.4110 - lr: 1.0000e-05\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4461 - categorical_crossentropy: 7.7797 - val_loss: 0.4496 - val_categorical_crossentropy: 7.3922 - lr: 1.0000e-05\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4466 - categorical_crossentropy: 7.7970 - val_loss: 0.4500 - val_categorical_crossentropy: 7.3783 - lr: 1.0000e-05\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4461 - categorical_crossentropy: 7.7552 - val_loss: 0.4496 - val_categorical_crossentropy: 7.3815 - lr: 1.0000e-05\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4427 - categorical_crossentropy: 7.7539 - val_loss: 0.4493 - val_categorical_crossentropy: 7.3960 - lr: 1.0000e-05\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4466 - categorical_crossentropy: 7.7741 - val_loss: 0.4493 - val_categorical_crossentropy: 7.3620 - lr: 1.0000e-05\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4447 - categorical_crossentropy: 7.7811 - val_loss: 0.4489 - val_categorical_crossentropy: 7.4010 - lr: 1.0000e-05\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4420 - categorical_crossentropy: 7.7386 - val_loss: 0.4491 - val_categorical_crossentropy: 7.3875 - lr: 1.0000e-05\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4436 - categorical_crossentropy: 7.7843 - val_loss: 0.4491 - val_categorical_crossentropy: 7.3961 - lr: 1.0000e-05\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4431 - categorical_crossentropy: 7.7279 - val_loss: 0.4488 - val_categorical_crossentropy: 7.3994 - lr: 1.0000e-05\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4422 - categorical_crossentropy: 7.7223 - val_loss: 0.4489 - val_categorical_crossentropy: 7.3930 - lr: 1.0000e-05\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4420 - categorical_crossentropy: 7.7638 - val_loss: 0.4488 - val_categorical_crossentropy: 7.4052 - lr: 1.0000e-05\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4408 - categorical_crossentropy: 7.7659 - val_loss: 0.4488 - val_categorical_crossentropy: 7.4010 - lr: 1.0000e-05\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4443 - categorical_crossentropy: 7.7554 - val_loss: 0.4490 - val_categorical_crossentropy: 7.3726 - lr: 1.0000e-05\n",
      "Epoch 31/200\n",
      "29/42 [===================>..........] - ETA: 0s - loss: 0.4456 - categorical_crossentropy: 7.7095Restoring model weights from the end of the best epoch: 26.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4412 - categorical_crossentropy: 7.7397 - val_loss: 0.4488 - val_categorical_crossentropy: 7.3939 - lr: 1.0000e-05\n",
      "Epoch 31: early stopping\n",
      "0.4487804174423218\n",
      "13/13 [==============================] - 0s 790us/step\n",
      "#################\n",
      "6\n",
      "#################\n",
      "Epoch 1/200\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 0.5762 - categorical_crossentropy: 9.2494 - val_loss: 0.4888 - val_categorical_crossentropy: 8.3844 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5086 - categorical_crossentropy: 8.4085 - val_loss: 0.4600 - val_categorical_crossentropy: 7.2491 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4912 - categorical_crossentropy: 8.3282 - val_loss: 0.4452 - val_categorical_crossentropy: 7.8203 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "40/42 [===========================>..] - ETA: 0s - loss: 0.4747 - categorical_crossentropy: 8.4100\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4759 - categorical_crossentropy: 8.3972 - val_loss: 0.4468 - val_categorical_crossentropy: 7.7250 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4601 - categorical_crossentropy: 8.1394 - val_loss: 0.4352 - val_categorical_crossentropy: 7.7769 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4502 - categorical_crossentropy: 8.0156 - val_loss: 0.4314 - val_categorical_crossentropy: 7.6415 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "39/42 [==========================>...] - ETA: 0s - loss: 0.4429 - categorical_crossentropy: 7.8840\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4427 - categorical_crossentropy: 7.8713 - val_loss: 0.4327 - val_categorical_crossentropy: 7.4815 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.4384 - categorical_crossentropy: 7.7582\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4401 - categorical_crossentropy: 7.7739 - val_loss: 0.4317 - val_categorical_crossentropy: 7.5730 - lr: 1.0000e-05\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4385 - categorical_crossentropy: 7.7930 - val_loss: 0.4314 - val_categorical_crossentropy: 7.5788 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4322 - categorical_crossentropy: 7.7947 - val_loss: 0.4312 - val_categorical_crossentropy: 7.5909 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4388 - categorical_crossentropy: 7.8315 - val_loss: 0.4314 - val_categorical_crossentropy: 7.5867 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4356 - categorical_crossentropy: 7.8165 - val_loss: 0.4313 - val_categorical_crossentropy: 7.6039 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4359 - categorical_crossentropy: 7.8172 - val_loss: 0.4311 - val_categorical_crossentropy: 7.5806 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4365 - categorical_crossentropy: 7.8130 - val_loss: 0.4309 - val_categorical_crossentropy: 7.5771 - lr: 1.0000e-05\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4358 - categorical_crossentropy: 7.8053 - val_loss: 0.4310 - val_categorical_crossentropy: 7.6042 - lr: 1.0000e-05\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4351 - categorical_crossentropy: 7.7749 - val_loss: 0.4310 - val_categorical_crossentropy: 7.5895 - lr: 1.0000e-05\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4330 - categorical_crossentropy: 7.7605 - val_loss: 0.4310 - val_categorical_crossentropy: 7.5870 - lr: 1.0000e-05\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4341 - categorical_crossentropy: 7.7814 - val_loss: 0.4311 - val_categorical_crossentropy: 7.5734 - lr: 1.0000e-05\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4299 - categorical_crossentropy: 7.7676 - val_loss: 0.4308 - val_categorical_crossentropy: 7.6107 - lr: 1.0000e-05\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4377 - categorical_crossentropy: 7.8473 - val_loss: 0.4310 - val_categorical_crossentropy: 7.5836 - lr: 1.0000e-05\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4342 - categorical_crossentropy: 7.7963 - val_loss: 0.4308 - val_categorical_crossentropy: 7.6089 - lr: 1.0000e-05\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4341 - categorical_crossentropy: 7.8105 - val_loss: 0.4307 - val_categorical_crossentropy: 7.6049 - lr: 1.0000e-05\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4314 - categorical_crossentropy: 7.7176 - val_loss: 0.4305 - val_categorical_crossentropy: 7.5880 - lr: 1.0000e-05\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4332 - categorical_crossentropy: 7.8295 - val_loss: 0.4307 - val_categorical_crossentropy: 7.5666 - lr: 1.0000e-05\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4335 - categorical_crossentropy: 7.6983 - val_loss: 0.4305 - val_categorical_crossentropy: 7.5558 - lr: 1.0000e-05\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4281 - categorical_crossentropy: 7.7465 - val_loss: 0.4305 - val_categorical_crossentropy: 7.5816 - lr: 1.0000e-05\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4289 - categorical_crossentropy: 7.7288 - val_loss: 0.4305 - val_categorical_crossentropy: 7.6150 - lr: 1.0000e-05\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4309 - categorical_crossentropy: 7.7877 - val_loss: 0.4304 - val_categorical_crossentropy: 7.5785 - lr: 1.0000e-05\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4293 - categorical_crossentropy: 7.7345 - val_loss: 0.4304 - val_categorical_crossentropy: 7.5934 - lr: 1.0000e-05\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4305 - categorical_crossentropy: 7.7548 - val_loss: 0.4304 - val_categorical_crossentropy: 7.5838 - lr: 1.0000e-05\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4335 - categorical_crossentropy: 7.7651 - val_loss: 0.4303 - val_categorical_crossentropy: 7.5925 - lr: 1.0000e-05\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4318 - categorical_crossentropy: 7.7394 - val_loss: 0.4304 - val_categorical_crossentropy: 7.5704 - lr: 1.0000e-05\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4303 - categorical_crossentropy: 7.7879 - val_loss: 0.4302 - val_categorical_crossentropy: 7.5887 - lr: 1.0000e-05\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4289 - categorical_crossentropy: 7.7278 - val_loss: 0.4304 - val_categorical_crossentropy: 7.5692 - lr: 1.0000e-05\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4293 - categorical_crossentropy: 7.7509 - val_loss: 0.4301 - val_categorical_crossentropy: 7.6091 - lr: 1.0000e-05\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4289 - categorical_crossentropy: 7.7700 - val_loss: 0.4301 - val_categorical_crossentropy: 7.5716 - lr: 1.0000e-05\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4301 - categorical_crossentropy: 7.7720 - val_loss: 0.4302 - val_categorical_crossentropy: 7.5696 - lr: 1.0000e-05\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4273 - categorical_crossentropy: 7.6835 - val_loss: 0.4299 - val_categorical_crossentropy: 7.5893 - lr: 1.0000e-05\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4247 - categorical_crossentropy: 7.6732 - val_loss: 0.4300 - val_categorical_crossentropy: 7.6178 - lr: 1.0000e-05\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4281 - categorical_crossentropy: 7.7860 - val_loss: 0.4300 - val_categorical_crossentropy: 7.6291 - lr: 1.0000e-05\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4275 - categorical_crossentropy: 7.7654 - val_loss: 0.4298 - val_categorical_crossentropy: 7.6254 - lr: 1.0000e-05\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4278 - categorical_crossentropy: 7.7586 - val_loss: 0.4298 - val_categorical_crossentropy: 7.5937 - lr: 1.0000e-05\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4279 - categorical_crossentropy: 7.7540 - val_loss: 0.4296 - val_categorical_crossentropy: 7.6280 - lr: 1.0000e-05\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4276 - categorical_crossentropy: 7.7882 - val_loss: 0.4296 - val_categorical_crossentropy: 7.5995 - lr: 1.0000e-05\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4268 - categorical_crossentropy: 7.7689 - val_loss: 0.4294 - val_categorical_crossentropy: 7.5929 - lr: 1.0000e-05\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4278 - categorical_crossentropy: 7.8144 - val_loss: 0.4292 - val_categorical_crossentropy: 7.6188 - lr: 1.0000e-05\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4277 - categorical_crossentropy: 7.7627 - val_loss: 0.4295 - val_categorical_crossentropy: 7.5937 - lr: 1.0000e-05\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4264 - categorical_crossentropy: 7.7818 - val_loss: 0.4295 - val_categorical_crossentropy: 7.5992 - lr: 1.0000e-05\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4280 - categorical_crossentropy: 7.7223 - val_loss: 0.4294 - val_categorical_crossentropy: 7.5711 - lr: 1.0000e-05\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4258 - categorical_crossentropy: 7.7178 - val_loss: 0.4295 - val_categorical_crossentropy: 7.6218 - lr: 1.0000e-05\n",
      "Epoch 51/200\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.4252 - categorical_crossentropy: 7.6965Restoring model weights from the end of the best epoch: 46.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4276 - categorical_crossentropy: 7.7786 - val_loss: 0.4294 - val_categorical_crossentropy: 7.6204 - lr: 1.0000e-05\n",
      "Epoch 51: early stopping\n",
      "0.4292227029800415\n",
      "13/13 [==============================] - 0s 917us/step\n",
      "#################\n",
      "7\n",
      "#################\n",
      "Epoch 1/200\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 0.5798 - categorical_crossentropy: 9.1651 - val_loss: 0.4773 - val_categorical_crossentropy: 7.6499 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.5113 - categorical_crossentropy: 8.7274 - val_loss: 0.4474 - val_categorical_crossentropy: 7.8028 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4928 - categorical_crossentropy: 8.4915 - val_loss: 0.4377 - val_categorical_crossentropy: 7.4533 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.4793 - categorical_crossentropy: 8.3527 - val_loss: 0.4315 - val_categorical_crossentropy: 7.7947 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.4655 - categorical_crossentropy: 8.1898\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4700 - categorical_crossentropy: 8.3647 - val_loss: 0.4373 - val_categorical_crossentropy: 8.1810 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4545 - categorical_crossentropy: 8.3244 - val_loss: 0.4244 - val_categorical_crossentropy: 7.8126 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4422 - categorical_crossentropy: 8.1116 - val_loss: 0.4223 - val_categorical_crossentropy: 7.8236 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "31/42 [=====================>........] - ETA: 0s - loss: 0.4378 - categorical_crossentropy: 7.9266\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4380 - categorical_crossentropy: 7.8713 - val_loss: 0.4231 - val_categorical_crossentropy: 7.6827 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4347 - categorical_crossentropy: 7.8538 - val_loss: 0.4222 - val_categorical_crossentropy: 7.7032 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4287 - categorical_crossentropy: 7.7976 - val_loss: 0.4221 - val_categorical_crossentropy: 7.7009 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4308 - categorical_crossentropy: 7.7849 - val_loss: 0.4218 - val_categorical_crossentropy: 7.7143 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.4278 - categorical_crossentropy: 7.7408\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4279 - categorical_crossentropy: 7.7782 - val_loss: 0.4221 - val_categorical_crossentropy: 7.7800 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4280 - categorical_crossentropy: 7.8820 - val_loss: 0.4220 - val_categorical_crossentropy: 7.7605 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4271 - categorical_crossentropy: 7.7796 - val_loss: 0.4221 - val_categorical_crossentropy: 7.7422 - lr: 1.0000e-05\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4302 - categorical_crossentropy: 7.7911 - val_loss: 0.4220 - val_categorical_crossentropy: 7.7532 - lr: 1.0000e-05\n",
      "Epoch 16/200\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.4299 - categorical_crossentropy: 7.8512Restoring model weights from the end of the best epoch: 11.\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4299 - categorical_crossentropy: 7.8467 - val_loss: 0.4218 - val_categorical_crossentropy: 7.7638 - lr: 1.0000e-05\n",
      "Epoch 16: early stopping\n",
      "0.42178255319595337\n",
      "13/13 [==============================] - 0s 735us/step\n",
      "#################\n",
      "8\n",
      "#################\n",
      "Epoch 1/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.5712 - categorical_crossentropy: 9.1010 - val_loss: 0.4982 - val_categorical_crossentropy: 8.4394 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4985 - categorical_crossentropy: 8.2200 - val_loss: 0.4974 - val_categorical_crossentropy: 8.8741 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4840 - categorical_crossentropy: 8.4442 - val_loss: 0.4819 - val_categorical_crossentropy: 8.2326 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4804 - categorical_crossentropy: 8.4835 - val_loss: 0.4808 - val_categorical_crossentropy: 8.2581 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4694 - categorical_crossentropy: 8.4535 - val_loss: 0.4760 - val_categorical_crossentropy: 8.8372 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.4662 - categorical_crossentropy: 8.5774\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4636 - categorical_crossentropy: 8.5445 - val_loss: 0.4864 - val_categorical_crossentropy: 8.4996 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4442 - categorical_crossentropy: 8.0762 - val_loss: 0.4629 - val_categorical_crossentropy: 8.4342 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.4319 - categorical_crossentropy: 7.9954\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4322 - categorical_crossentropy: 7.9847 - val_loss: 0.4643 - val_categorical_crossentropy: 8.4567 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4253 - categorical_crossentropy: 7.9297 - val_loss: 0.4627 - val_categorical_crossentropy: 8.3079 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.4258 - categorical_crossentropy: 7.7439\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4248 - categorical_crossentropy: 7.7577 - val_loss: 0.4627 - val_categorical_crossentropy: 8.2846 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4250 - categorical_crossentropy: 7.7440 - val_loss: 0.4624 - val_categorical_crossentropy: 8.2764 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4234 - categorical_crossentropy: 7.8160 - val_loss: 0.4626 - val_categorical_crossentropy: 8.2746 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4238 - categorical_crossentropy: 7.7727 - val_loss: 0.4627 - val_categorical_crossentropy: 8.2974 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4256 - categorical_crossentropy: 7.7986 - val_loss: 0.4624 - val_categorical_crossentropy: 8.2796 - lr: 1.0000e-05\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4212 - categorical_crossentropy: 7.8281 - val_loss: 0.4624 - val_categorical_crossentropy: 8.2824 - lr: 1.0000e-05\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4221 - categorical_crossentropy: 7.7654 - val_loss: 0.4625 - val_categorical_crossentropy: 8.2983 - lr: 1.0000e-05\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4243 - categorical_crossentropy: 7.8012 - val_loss: 0.4620 - val_categorical_crossentropy: 8.2415 - lr: 1.0000e-05\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4193 - categorical_crossentropy: 7.6902 - val_loss: 0.4620 - val_categorical_crossentropy: 8.2425 - lr: 1.0000e-05\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4209 - categorical_crossentropy: 7.7726 - val_loss: 0.4624 - val_categorical_crossentropy: 8.2740 - lr: 1.0000e-05\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4203 - categorical_crossentropy: 7.7227 - val_loss: 0.4626 - val_categorical_crossentropy: 8.3016 - lr: 1.0000e-05\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4210 - categorical_crossentropy: 7.7669 - val_loss: 0.4625 - val_categorical_crossentropy: 8.2898 - lr: 1.0000e-05\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4179 - categorical_crossentropy: 7.7365 - val_loss: 0.4623 - val_categorical_crossentropy: 8.2929 - lr: 1.0000e-05\n",
      "Epoch 23/200\n",
      "32/42 [=====================>........] - ETA: 0s - loss: 0.4190 - categorical_crossentropy: 7.6642Restoring model weights from the end of the best epoch: 18.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4173 - categorical_crossentropy: 7.7345 - val_loss: 0.4624 - val_categorical_crossentropy: 8.2743 - lr: 1.0000e-05\n",
      "Epoch 23: early stopping\n",
      "0.4619810879230499\n",
      "13/13 [==============================] - 0s 734us/step\n",
      "#################\n",
      "9\n",
      "#################\n",
      "Epoch 1/200\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5735 - categorical_crossentropy: 9.1982 - val_loss: 0.4717 - val_categorical_crossentropy: 7.0187 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.5035 - categorical_crossentropy: 8.6614 - val_loss: 0.4550 - val_categorical_crossentropy: 6.8835 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4909 - categorical_crossentropy: 8.4563 - val_loss: 0.4514 - val_categorical_crossentropy: 7.4917 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "33/42 [======================>.......] - ETA: 0s - loss: 0.4863 - categorical_crossentropy: 8.5401\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4849 - categorical_crossentropy: 8.5977 - val_loss: 0.4604 - val_categorical_crossentropy: 7.7643 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4568 - categorical_crossentropy: 8.2062 - val_loss: 0.4472 - val_categorical_crossentropy: 7.6352 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4450 - categorical_crossentropy: 7.9934 - val_loss: 0.4455 - val_categorical_crossentropy: 7.3422 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4405 - categorical_crossentropy: 7.9355 - val_loss: 0.4440 - val_categorical_crossentropy: 7.5080 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "38/42 [==========================>...] - ETA: 0s - loss: 0.4310 - categorical_crossentropy: 7.9205\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4339 - categorical_crossentropy: 7.9595 - val_loss: 0.4439 - val_categorical_crossentropy: 7.3139 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4355 - categorical_crossentropy: 7.8314 - val_loss: 0.4435 - val_categorical_crossentropy: 7.3801 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "35/42 [========================>.....] - ETA: 0s - loss: 0.4334 - categorical_crossentropy: 7.8099\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4317 - categorical_crossentropy: 7.8748 - val_loss: 0.4437 - val_categorical_crossentropy: 7.3922 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4333 - categorical_crossentropy: 7.8423 - val_loss: 0.4438 - val_categorical_crossentropy: 7.3754 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4336 - categorical_crossentropy: 7.8896 - val_loss: 0.4438 - val_categorical_crossentropy: 7.3908 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4285 - categorical_crossentropy: 7.7703 - val_loss: 0.4438 - val_categorical_crossentropy: 7.3891 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "41/42 [============================>.] - ETA: 0s - loss: 0.4317 - categorical_crossentropy: 7.9103Restoring model weights from the end of the best epoch: 9.\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4315 - categorical_crossentropy: 7.8967 - val_loss: 0.4438 - val_categorical_crossentropy: 7.4094 - lr: 1.0000e-05\n",
      "Epoch 14: early stopping\n",
      "0.4435490667819977\n",
      "13/13 [==============================] - 0s 957us/step\n"
     ]
    }
   ],
   "source": [
    "skf = KFold(n_splits=9, shuffle=True, random_state=1234)\n",
    "Final_Subbmission = []\n",
    "val_loss_print = []\n",
    "i=1\n",
    "for train_index, test_index in skf.split(X_train,Y_train):\n",
    "    keras.backend.clear_session()\n",
    "    print('#################')\n",
    "    print(i)\n",
    "    print('#################')\n",
    "    X_train1, X_test1 = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_test = Y_train.iloc[train_index], Y_train.iloc[test_index]\n",
    "    model = wider_model()\n",
    "    val_ds = (X_test1,y_test)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=1,min_lr=1e-05,verbose=1)\n",
    "    early_stoping = EarlyStopping(monitor=\"val_loss\",min_delta=0,patience=5,verbose=1,mode=\"auto\", baseline=None,restore_best_weights=True)\n",
    "    model.compile(loss='binary_crossentropy',metrics='categorical_crossentropy', optimizer='Adam')\n",
    "    histroy = model.fit(X_train1,y_train, validation_data=val_ds,epochs=200,callbacks=[reduce_lr,early_stoping],verbose=1,batch_size=34)\n",
    "    print(min(histroy.history['val_loss']))\n",
    "    val_loss_print.append(min(histroy.history['val_loss']))\n",
    "    Test_seq_pred = model.predict(X_test)\n",
    "    Final_Subbmission.append(Test_seq_pred)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_prob =np.mean(Final_Subbmission,0)\n",
    "Test_prob = pd.DataFrame(Test_prob)\n",
    "Test_prob.columns = comments_labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted: 0.74 \n"
     ]
    }
   ],
   "source": [
    "test_y1 = Y_test.reset_index(drop=True)\n",
    "print(\"weighted: {:.2f} \".format( metrics.average_precision_score(test_y1, Test_prob, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test.values.ravel(), Test_prob.values.ravel())\n",
    "optimal_threshold = thresholds[np.argmax(tpr - fpr)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       338\n",
      "           1       0.82      1.00      0.90       329\n",
      "           2       0.53      0.62      0.57       148\n",
      "           3       0.51      0.86      0.64       190\n",
      "           4       0.43      0.48      0.45        88\n",
      "           5       0.71      0.24      0.36        42\n",
      "           6       0.58      0.72      0.64       154\n",
      "           7       0.57      0.09      0.15        47\n",
      "           8       0.60      0.42      0.50        78\n",
      "\n",
      "   micro avg       0.68      0.79      0.73      1414\n",
      "   macro avg       0.62      0.60      0.57      1414\n",
      "weighted avg       0.68      0.79      0.72      1414\n",
      " samples avg       0.68      0.81      0.71      1414\n",
      "\n",
      "Overall Accuracy: 10.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Convert continuous values to discrete class labels\n",
    "Test_prob_discrete = Test_prob.apply(lambda x: [1 if val >= optimal_threshold else 0 for val in x])\n",
    "\n",
    "report = classification_report(test_y1, Test_prob_discrete, zero_division=1)\n",
    "acc = metrics.accuracy_score(test_y1, Test_prob_discrete)\n",
    "print(\"Classification Report: \\n\", report)\n",
    "print(\"Overall Accuracy: {:.2f}\".format(acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34980062"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>Tag6</th>\n",
       "      <th>Tag7</th>\n",
       "      <th>Tag8</th>\n",
       "      <th>Tag9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tag1  Tag2  Tag3  Tag4  Tag5  Tag6  Tag7  Tag8  Tag9\n",
       "0       1     1     1     1     0     0     0     1     0\n",
       "1       1     1     0     1     0     0     0     0     0\n",
       "2       1     1     0     0     0     0     1     0     0\n",
       "3       1     1     1     0     1     1     0     0     0\n",
       "4       1     1     0     0     0     0     0     0     0\n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
       "396     0     1     0     0     1     0     0     0     0\n",
       "397     0     1     0     0     0     0     1     0     0\n",
       "398     1     1     1     1     1     0     1     0     0\n",
       "399     1     0     1     0     0     0     0     0     0\n",
       "400     1     1     0     1     0     0     0     0     1\n",
       "\n",
       "[401 rows x 9 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>Tag6</th>\n",
       "      <th>Tag7</th>\n",
       "      <th>Tag8</th>\n",
       "      <th>Tag9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>401 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Tag1  Tag2  Tag3  Tag4  Tag5  Tag6  Tag7  Tag8  Tag9\n",
       "0       1     1     1     1     0     0     0     0     0\n",
       "1       1     1     0     1     0     0     1     0     0\n",
       "2       1     1     1     1     1     0     1     0     0\n",
       "3       1     1     1     1     0     0     0     0     1\n",
       "4       1     1     0     0     0     0     0     0     0\n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
       "396     1     1     0     1     0     0     0     0     0\n",
       "397     1     1     0     0     0     0     1     0     0\n",
       "398     1     1     1     1     0     0     1     0     0\n",
       "399     1     1     1     1     0     0     1     0     0\n",
       "400     1     1     1     1     0     0     0     0     0\n",
       "\n",
       "[401 rows x 9 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_prob_discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Assuming you have the true labels Y_test and predicted probabilities Test_prob\n",
    "fpr, tpr, thresholds = roc_curve(Y_test.values.ravel(), Test_prob.values.ravel())\n",
    "\n",
    "# Plotting the ROC curve\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = {'i want to die', 'this world is so fucking shit', 'i wish i was dead'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Define a function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeldict ={'Feeling-bad-about-yourself-or-that-you-are-a-failure-or-have-let-yourself-or-your-family-down': 0,\n",
    "            'Feeling-down-depressed-or-hopeless': 1, \n",
    "            'Feeling-tired-or-having-little-energy': 2, \n",
    "            'Little-interest-or-pleasure-in-doing ': 3,\n",
    "            'Moving-or-speaking-so-slowly-that-other-people-could-have-noticed-Or-the-opposite-being-so-fidgety-or-restless-that-you-have-been-moving-around-a-lot-more-than-usual':4, \n",
    "            'Poor-appetite-or-overeating': 5, \n",
    "            'Thoughts-that-you-would-be-better-off-dead-or-of-hurting-yourself-in-some-way': 6, \n",
    "            'Trouble-concentrating-on-things-such-as-reading-the-newspaper-or-watching-television': 7, \n",
    "            'Trouble-falling-or-staying-asleep-or-sleeping-too-much': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name google-bert/bert-base-uncased. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "embedder = SentenceTransformer('google-bert/bert-base-uncased')\n",
    "embedder.max_seq_length = 512\n",
    "results = {}\n",
    "for input_string in ip:\n",
    "    # Preprocess the input string\n",
    "    processed_input = preprocess_text(input_string)\n",
    "\n",
    "    # Encode the processed input using the SentenceTransformer model\n",
    "    embedded_input = embedder.encode([processed_input], show_progress_bar=False)\n",
    "\n",
    "    # Make predictions for the input\n",
    "    input_predictions = model.predict(embedded_input)\n",
    "    input_predictions = pd.DataFrame(input_predictions)\n",
    "    input_predictions = input_predictions.apply(lambda x: [1 if val >= 0.349802 else 0 for val in x])\n",
    "\n",
    "    # Get the labels for input predictions\n",
    "    input_predicted_labels = [(label, \"yes\" if input_predictions[value][0] == 1 else \"no\") for label, value in labeldict.items()]\n",
    "\n",
    "    # Store the result in the dictionary\n",
    "    results[input_string] = input_predicted_labels\n",
    "\n",
    "# Ensure that all variables and functions are used correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for input_string in ip:\n",
    "    # Preprocess the input string\n",
    "    processed_input = preprocess_text(input_string)\n",
    "\n",
    "    # Encode the processed input using the SentenceTransformer model\n",
    "    embedded_input = embedder.encode([processed_input], show_progress_bar=False)\n",
    "\n",
    "    # Make predictions for the input\n",
    "    input_predictions = model.predict(embedded_input)\n",
    "    input_predictions = pd.DataFrame(input_predictions)\n",
    "    input_predictions = input_predictions.apply(lambda x: [1 if val >= 0.349802 else 0 for val in x])\n",
    "\n",
    "    # Get the labels for input predictions\n",
    "    input_predicted_labels = [(label, \"yes\" if input_predictions[value][0] == 1 else \"no\") for label, value in labeldict.items()]\n",
    "\n",
    "    # Store the result in the dictionary\n",
    "    results[input_string] = input_predicted_labels\n",
    "\n",
    "# Ensure that all variables and functions are used correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this world is so fucking shit': [('Feeling-bad-about-yourself-or-that-you-are-a-failure-or-have-let-yourself-or-your-family-down', 'yes'), ('Feeling-down-depressed-or-hopeless', 'yes'), ('Feeling-tired-or-having-little-energy', 'no'), ('Little-interest-or-pleasure-in-doing ', 'no'), ('Moving-or-speaking-so-slowly-that-other-people-could-have-noticed-Or-the-opposite-being-so-fidgety-or-restless-that-you-have-been-moving-around-a-lot-more-than-usual', 'no'), ('Poor-appetite-or-overeating', 'no'), ('Thoughts-that-you-would-be-better-off-dead-or-of-hurting-yourself-in-some-way', 'no'), ('Trouble-concentrating-on-things-such-as-reading-the-newspaper-or-watching-television', 'no'), ('Trouble-falling-or-staying-asleep-or-sleeping-too-much', 'no')], 'i want to die': [('Feeling-bad-about-yourself-or-that-you-are-a-failure-or-have-let-yourself-or-your-family-down', 'yes'), ('Feeling-down-depressed-or-hopeless', 'no'), ('Feeling-tired-or-having-little-energy', 'yes'), ('Little-interest-or-pleasure-in-doing ', 'no'), ('Moving-or-speaking-so-slowly-that-other-people-could-have-noticed-Or-the-opposite-being-so-fidgety-or-restless-that-you-have-been-moving-around-a-lot-more-than-usual', 'no'), ('Poor-appetite-or-overeating', 'yes'), ('Thoughts-that-you-would-be-better-off-dead-or-of-hurting-yourself-in-some-way', 'yes'), ('Trouble-concentrating-on-things-such-as-reading-the-newspaper-or-watching-television', 'no'), ('Trouble-falling-or-staying-asleep-or-sleeping-too-much', 'no')], 'i wish i was dead': [('Feeling-bad-about-yourself-or-that-you-are-a-failure-or-have-let-yourself-or-your-family-down', 'yes'), ('Feeling-down-depressed-or-hopeless', 'yes'), ('Feeling-tired-or-having-little-energy', 'yes'), ('Little-interest-or-pleasure-in-doing ', 'no'), ('Moving-or-speaking-so-slowly-that-other-people-could-have-noticed-Or-the-opposite-being-so-fidgety-or-restless-that-you-have-been-moving-around-a-lot-more-than-usual', 'no'), ('Poor-appetite-or-overeating', 'no'), ('Thoughts-that-you-would-be-better-off-dead-or-of-hurting-yourself-in-some-way', 'yes'), ('Trouble-concentrating-on-things-such-as-reading-the-newspaper-or-watching-television', 'no'), ('Trouble-falling-or-staying-asleep-or-sleeping-too-much', 'yes')]}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
